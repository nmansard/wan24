{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaching multiple targets with a manipulator\n",
    "The objective of this exercice is to introduce the implementation of the front-end based on Pinocchio, for polyarticulated systems modeled in position-velocity-torque.\n",
    "\n",
    "We provide a basic example for reaching one point with a manipulator robot. You are then guided to modify this example for sequence of multiple targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: as for all the tutorials, a magic command %do_not_load is introduced to hide\n",
      "    the solutions to some questions. Change it for %load if you want to see (and\n",
      "    execute) the solution.\n"
     ]
    }
   ],
   "source": [
    "import gepetuto.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is also based on Crocoddyl. Our optimal control toolbox is composed of 3 main parts: **the backend** contains the API for solving the problem and accessing the solution and implements several solvers, DDP being the first one; **the frontend** is first composed of a basic API which we mostly used in the exercice with unicycle and bicopter, and that you can use to implement any fancy problem; finally, **a particular implementation of the front end using Pinocchio** is mostly written for working with polyarticulated systems such as manipulator robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need crocoddyl as in the previous notebook, with the model of the arm of the humanoid robot Talos, a 7-dof arm. It can be found in example robot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_import\n",
    "import crocoddyl\n",
    "import pinocchio as pin\n",
    "import numpy as np\n",
    "import example_robot_data as robex\n",
    "import matplotlib.pylab as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will give an introduction to the multibody (Pinocchio) front-end of Crocoddyl. In the first part, we will use the classical DDP solver (back-end). In the second part, we will use the more recent MIM Solver, which can handle hard constraint. It is available in the PyPI package [cmeel-mim-solvers](https://pypi.org/project/cmeel-mim-solvers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmeel-mim-solvers in ./.venv/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: cmeel in ./.venv/lib/python3.10/site-packages (from cmeel-mim-solvers) (0.53.3)\n",
      "Requirement already satisfied: crocoddyl in ./.venv/lib/python3.10/site-packages (from cmeel-mim-solvers) (2.0.2)\n",
      "Requirement already satisfied: proxsuite in ./.venv/lib/python3.10/site-packages (from cmeel-mim-solvers) (0.6.3)\n",
      "Requirement already satisfied: cmeel-boost~=1.83.0 in ./.venv/lib/python3.10/site-packages (from cmeel-mim-solvers) (1.83.0)\n",
      "Requirement already satisfied: numpy~=1.26.0 in ./.venv/lib/python3.10/site-packages (from cmeel-boost~=1.83.0->cmeel-mim-solvers) (1.26.4)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in ./.venv/lib/python3.10/site-packages (from cmeel->cmeel-mim-solvers) (2.0.1)\n",
      "Requirement already satisfied: example-robot-data in ./.venv/lib/python3.10/site-packages (from crocoddyl->cmeel-mim-solvers) (4.1.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from proxsuite->cmeel-mim-solvers) (1.12.0)\n",
      "Requirement already satisfied: pin in ./.venv/lib/python3.10/site-packages (from example-robot-data->crocoddyl->cmeel-mim-solvers) (2.7.0)\n",
      "Requirement already satisfied: cmeel-urdfdom<4,>=3.1.1.1 in ./.venv/lib/python3.10/site-packages (from pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (3.1.1.1)\n",
      "Requirement already satisfied: hpp-fcl<4,>=2.3.4 in ./.venv/lib/python3.10/site-packages (from pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (2.4.1)\n",
      "Requirement already satisfied: cmeel-console-bridge in ./.venv/lib/python3.10/site-packages (from cmeel-urdfdom<4,>=3.1.1.1->pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (1.0.2.2)\n",
      "Requirement already satisfied: cmeel-tinyxml in ./.venv/lib/python3.10/site-packages (from cmeel-urdfdom<4,>=3.1.1.1->pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (2.6.2.3)\n",
      "Requirement already satisfied: cmeel-assimp<6,>=5.3.1 in ./.venv/lib/python3.10/site-packages (from hpp-fcl<4,>=2.3.4->pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (5.3.1)\n",
      "Requirement already satisfied: cmeel-octomap<2,>=1.9.8.2 in ./.venv/lib/python3.10/site-packages (from hpp-fcl<4,>=2.3.4->pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (1.9.8.2)\n",
      "Requirement already satisfied: cmeel-qhull<8.0.3,>=8.0.2.1 in ./.venv/lib/python3.10/site-packages (from hpp-fcl<4,>=2.3.4->pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (8.0.2.1)\n",
      "Requirement already satisfied: eigenpy<4,>=3.1 in ./.venv/lib/python3.10/site-packages (from hpp-fcl<4,>=2.3.4->pin->example-robot-data->crocoddyl->cmeel-mim-solvers) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cmeel-mim-solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mim_solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panda reaches a single target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda robot model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the Pinocchio model for the Panda arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_robexload\n",
    "# First, let's load the Pinocchio model for the Panda arm.\n",
    "robot = robex.load('panda')\n",
    "# The 2 last joints are for the fingers, not important in arm motion, freeze them\n",
    "robot.model,[robot.visual_model,robot.collision_model] = \\\n",
    "    pin.buildReducedModel(robot.model,[robot.visual_model,robot.collision_model],[8,9],robot.q0)\n",
    "robot.q0 = robot.q0[:7].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal control problem is defined by a bunch of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_hyperparameters\n",
    "HORIZON_LENGTH = 100\n",
    "TIME_STEP = 1e-2\n",
    "FRAME_TIP = robot.model.getFrameId(\"panda_hand_tcp\")\n",
    "GOAL_POSITION = np.array([.2,0.6,.5])\n",
    "GOAL_PLACEMENT = pin.SE3(pin.utils.rpyToMatrix(-np.pi,-1.5,1.5), GOAL_POSITION)\n",
    "REACH_DIMENSION = \"3d\" # \"6d\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set robot model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_robot_model\n",
    "# Set robot model\n",
    "robot_model = robot.model\n",
    "robot_model.armature = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.])*5\n",
    "robot_model.q0 = np.array([3.5,2,2,0,0,0,0])\n",
    "robot_model.x0 = np.concatenate([robot_model.q0, np.zeros(robot_model.nv)])\n",
    "robot_model.gravity *= 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use meshcat for displaying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** You asked to start meshcat \"classically\" in tcp://127.0.0.1:6000\n",
      "*** Did you start meshcat manually (meshcat-server)\n",
      "Wrapper tries to connect to server <tcp://127.0.0.1:6000>\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_viz\n",
    "from supaero2024.meshcat_viewer_wrapper import MeshcatVisualizer\n",
    "viz = MeshcatVisualizer(robot)\n",
    "viz.display(robot.q0)\n",
    "viz.addBox('world/goal',[.1,.1,.1],[0,1,0,1])\n",
    "viz.applyConfiguration('world/goal',GOAL_PLACEMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is augmented with a default state $x_0$, and armature is added to the joints to model the gear reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_robot_model\n",
    "# Set robot model\n",
    "robot_model = robot.model\n",
    "robot_model.armature = np.ones(robot.model.nv)*2 # Arbitrary value representing the true armature\n",
    "robot_model.q0 = robot.q0.copy()\n",
    "robot_model.x0 = np.concatenate([robot_model.q0, np.zeros(robot_model.nv)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and dynamics\n",
    "This starts with specifying the state space, defined by $x=(q,v)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_state\n",
    "state = crocoddyl.StateMultibody(robot_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost is defined as a sum of multiple terms. The classes CostSum are created to store the terms. Let's have one for the running nodes, and one for the terminal node.\n",
    "\n",
    "We need to first define a cost model (i.e. set of cost functions) in order to next define the action model for our optimal control problem.\n",
    "For this particular example, we formulate three running-cost functions: goal-tracking cost, state and control regularization; and a terminal cost: goal cost. First, let's create the common cost functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_sumofcosts\n",
    "runningCostModel = crocoddyl.CostModelSum(state)\n",
    "terminalCostModel = crocoddyl.CostModelSum(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a cost for reaching the target, either as a 3D objective $\\ell(x) = \\| p(q)-p^*\\|^2$, or as a 6D objective $\\ell(x) = \\| \\log( \\ ^0M_E(q)^{-1} \\ ^0M_* ) \\|^2$, with $p^* \\in \\mathbb{R^3}$ the goal position, and $^0M_* \\in SE(3)$ the goal placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_cost_goal\n",
    "if REACH_DIMENSION == \"3d\":\n",
    "    # Cost for 3d tracking || p(q) - pref ||**2\n",
    "    goalTrackingRes = crocoddyl.ResidualModelFrameTranslation(state,FRAME_TIP,GOAL_POSITION)\n",
    "    goalTrackingWeights = crocoddyl.ActivationModelWeightedQuad(np.array([1,1,1]))\n",
    "elif REACH_DIMENSION == \"6d\":\n",
    "    # Cost for 6d tracking  || log( M(q)^-1 Mref ) ||**2\n",
    "    goalTrackingRes = crocoddyl.ResidualModelFramePlacement(state,FRAME_TIP,GOAL_PLACEMENT)\n",
    "    goalTrackingWeights = crocoddyl.ActivationModelWeightedQuad(np.array([1,1,1, 1,1,1]))\n",
    "else:\n",
    "    assert( REACH_DIMENSION==\"3d\" or REACH_DIMENSION==\"6d\" )\n",
    "goalTrackingCost = crocoddyl.CostModelResidual(state,goalTrackingWeights,goalTrackingRes)\n",
    "runningCostModel.addCost(\"gripperPose\", goalTrackingCost, .001)\n",
    "terminalCostModel.addCost(\"gripperPose\", goalTrackingCost, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add regularization. First a state regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_cost_xreg\n",
    "# Cost for state regularization || x - x* ||**2\n",
    "# We set up different values for the integral cost and terminal cost term.\n",
    "\n",
    "# Regularization is stronger on position than velocity (to account for typical unit scale)\n",
    "xRegWeights = crocoddyl.ActivationModelWeightedQuad(np.array([1,1,1,1,1,1,1, .1,.1,.1,.1,.1,.1,.1]))\n",
    "xRegRes = crocoddyl.ResidualModelState(state,robot_model.x0)\n",
    "xRegCost = crocoddyl.CostModelResidual(state,xRegWeights,xRegRes)\n",
    "runningCostModel.addCost(\"xReg\", xRegCost, 1e-3)\n",
    "\n",
    "# Terminal cost for state regularization || x - x* ||**2\n",
    "# Require more strictly a small velocity at task end (but we don't car for the position)\n",
    "xRegWeightsT=crocoddyl.ActivationModelWeightedQuad(np.array([.5,.5,.5,.5,.5,.5,.5,  5.,5.,5.,5.,5.,5.,5.]))\n",
    "xRegResT = crocoddyl.ResidualModelState(state,robot_model.x0)\n",
    "xRegCostT = crocoddyl.CostModelResidual(state,xRegWeightsT,xRegResT)\n",
    "terminalCostModel.addCost(\"xReg\", xRegCostT, .01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a control regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_cost_ureg\n",
    "# Cost for control regularization || u - g(q) ||**2\n",
    "uRegRes = crocoddyl.ResidualModelControlGrav(state)\n",
    "uRegCost = crocoddyl.CostModelResidual(state,uRegRes)\n",
    "runningCostModel.addCost(\"uReg\", uRegCost, 1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Action model \n",
    "Next, we need to create an action model for running and terminal nodes. We follow the same logic already explained with the bicopter: a differential action model (DAM) for the forward dynamics and the cost integrals, then a numerical integration in the integrator action model (IAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_iam\n",
    "# Next, we need to create the running and terminal action model.\n",
    "# The forward dynamics (computed using ABA) are implemented\n",
    "# inside DifferentialActionModelFullyActuated.\n",
    "\n",
    "# The actuation model is here trivial: tau_q = u.\n",
    "actuationModel = crocoddyl.ActuationModelFull(state)\n",
    "# Running model composing the costs, the differential equations of motion and the integrator.\n",
    "runningModel = crocoddyl.IntegratedActionModelEuler(\n",
    "    crocoddyl.DifferentialActionModelFreeFwdDynamics(state, actuationModel, runningCostModel), TIME_STEP)\n",
    "runningModel.differential.armature = robot_model.armature\n",
    "# Terminal model following the same logic, although the integration is here trivial.\n",
    "terminalModel = crocoddyl.IntegratedActionModelEuler(\n",
    "    crocoddyl.DifferentialActionModelFreeFwdDynamics(state, actuationModel, terminalCostModel), 0.)\n",
    "terminalModel.differential.armature = robot_model.armature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Optimal control problem \n",
    "Once we have the action models, we just have to shape them into an optimal control problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_shoot\n",
    "problem = crocoddyl.ShootingProblem(robot_model.x0, [runningModel] * HORIZON_LENGTH, terminalModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solve and display\n",
    "We finalize the set up by creating the DDP solver for this optimal control problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_solve\n",
    "# Solving it using DDP\n",
    "# Create the DDP solver for this OC problem, verbose traces, with a logger\n",
    "ddp = crocoddyl.SolverDDP(problem)\n",
    "ddp.setCallbacks([\n",
    "    crocoddyl.CallbackLogger(),\n",
    "    crocoddyl.CallbackVerbose(),\n",
    "])\n",
    "\n",
    "# Solving it with the DDP algorithm\n",
    "ddp.solve([],[],1000)  # xs_init,us_init,maxiter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now look at the results, either by plotting it or animating the trajectory in the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_plot\n",
    "# Plotting the solution and the DDP convergence\n",
    "log = ddp.getCallbacks()[0]\n",
    "crocoddyl.plotOCSolution(log.xs, log.us, figIndex=1, show=False)\n",
    "crocoddyl.plotConvergence(\n",
    "    log.costs,\n",
    "    log.pregs,\n",
    "    log.dregs,\n",
    "    log.grads,\n",
    "    log.stops,\n",
    "    log.steps,\n",
    "    figIndex=2,\n",
    "    show=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_a_single_target_animate\n",
    "# # Visualizing the solution in gepetto-viewer\n",
    "viz.play([x[:robot.model.nq] for x in ddp.xs],TIME_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the example for reaching a sequence of targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Now we ask you to modify this example to reach a sequence of targets $p_{*1},p_{*2},p_{*3},p_{*4}$. The optimal trajectory should use similar regularization, but with the reaching cost now varying it time: for the first quarter of nodes, the target is $p_{*1}$, then another quarter with $p_{*2}$ etc until the four targets are reached. Don't specify a particular velocity when reaching the point to let more freedom to the solver.\n",
    "\n",
    "Below is a quick guideline to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### First step: prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Start by defining several targets (let's say 4 targets, all at x=0.4, and at y and z being either 0 or 0.4), and display then in the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Second step: define the shooting problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The shooting problem will be composed of 4 sequences of action models. Each sequence consists on T shooting \"running\" nodes and 1 terminal node. The running nodes mostly have regularization terms, while the terminal nodes have a strong cost toward the respective target.\n",
    "\n",
    "$[ R_1,R_1,R_1 ... R_1,T_1, R_2,R_2 .... R_2, T_2, R_3 ... R_3, T_3, R_4 ... R_4 ] , T4\n",
    "\n",
    "First create 4 running models and 4 terminal models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to add a position cost, and state and control regularization to each running action model. Please  note that for terminal action model is only needed the position cost. Additionally, in the running models, the position cost should be low, and it should be high in the terminal models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a shooting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq0 = [runningModels[0]]*T + [terminalModels[0]]\n",
    "seq1 = [runningModels[1]]*T + [terminalModels[1]]\n",
    "seq2 = [runningModels[2]]*T + [terminalModels[2]]\n",
    "seq3 = [runningModels[3]]*T \n",
    "problem = crocoddyl.ShootingProblem(x0,seq0+seq1+seq2+seq3,terminalmodel[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DDP solver for this problem and run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp = crocoddyl.SolverDDP(problem)\n",
    "ddp.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it should not work, at least no on the first shot. The DDP solver is likely not strong enough to accept the random weights that you have selected. \n",
    "\n",
    "If it is working nicely from the first shot, display it in the viewer and go take a coffee. But you will likely have to tweak the gains to make it work.\n",
    "\n",
    "**It is suggested to first optimize only sequence 1. When you are happy with it, add sequence 2 and optimize again, etc.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Toward hard constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The solver works with double precisions, so it is quite robust to high weight. 10000 is likely to be accepted for example. But if you make the problem too difficult, the solver will break. \n",
    "In that case, you can implement a simple penalty solver by setting the weight to be 10**i, and creating a for loop to explore i from 0 to 5. At each iteration of the loop, run the solver from the previous solution and for few iterations only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    for m in terminalModels:\n",
    "        m.costs.costs['gripperPose'].weight = 10**i\n",
    "    ddp.solve(ddp.xs, ddp.us, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This not very convenient, and a better solver should be used if you really want imposing hard constraints. Let's do that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Adding hard constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIM Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last chapter, we guide you through the advanced, more recent, constraint interface. It is composed of two parts. First, constraints can be defined in the front end, following a similar logic to costs, and using again the residual models. That should be pretty straight forward now you are proficient with cost models. Second, we need another solver. DDP is not aware of constraints and would just skip them. More advanced solvers are available. We propose here to use the recent SQP from the team \"Machine in Motion\" led by Ludovic Righetti at NYU, described in \n",
    "https://laas.hal.science/hal-04330251\n",
    "\n",
    "The implementation of the solver is available is the GitHub repository https://github.com/machines-in-motion/mim_solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Preparing the environment\n",
    "For this example, we will impose a virtual wall in front of the robot, with the following parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_hyperparameters\n",
    "X_WALL_LOWER = .25\n",
    "X_WALL_UPPER = .35\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the constraints\n",
    "\n",
    "Similarly to the sum-of-costs, all constraints must be stored in a constraint manager, which is given as initial argument when building a differential action model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_constraint_manager\n",
    "# Define contraint\n",
    "runningConstraints = crocoddyl.ConstraintModelManager(state, robot.nv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose here to introduce a virtual wall constraining the end effector. For that, we use the same frame-translation residual. The constraint is defined along each axis with constant bounds, and np.inf when a particular direction should not be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_eewall\n",
    "# Create contraint on end-effector\n",
    "frameTranslationResidual = crocoddyl.ResidualModelFrameTranslation(\n",
    "    state, FRAME_TIP, np.zeros(3)\n",
    ")\n",
    "eeWallContraint = crocoddyl.ConstraintModelResidual(\n",
    "    state,\n",
    "    frameTranslationResidual,\n",
    "    np.array([X_WALL_LOWER, -np.inf, -np.inf]),\n",
    "    np.array([X_WALL_UPPER, +np.inf, +np.inf]),\n",
    ")\n",
    "runningConstraints.addConstraint(\"ee_wall\", eeWallContraint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can build a new action model with this constraint. We advise you don't constrain the initial node, as it easily leads to a unfeasible problem if $x_0$ does not satisfy the constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_iam\n",
    "# Next, we need to create the running and terminal action model.\n",
    "# The forward dynamics (computed using ABA) are implemented\n",
    "# inside DifferentialActionModelFullyActuated.\n",
    "\n",
    "# The actuation model is here trivial: tau_q = u.\n",
    "actuationModel = crocoddyl.ActuationModelFull(state)\n",
    "# Running model composing the costs, the differential equations of motion and the integrator.\n",
    "runningModel = crocoddyl.IntegratedActionModelEuler(\n",
    "    crocoddyl.DifferentialActionModelFreeFwdDynamics(\n",
    "        state, actuationModel, runningCostModel, runningConstraints),\n",
    "    TIME_STEP)\n",
    "runningModel.differential.armature = robot_model.armature\n",
    "# Specific unconstrained initial model\n",
    "runningModel_init = crocoddyl.IntegratedActionModelEuler(\n",
    "    crocoddyl.DifferentialActionModelFreeFwdDynamics(\n",
    "        state, actuationModel, runningCostModel),\n",
    "    TIME_STEP)\n",
    "runningModel.differential.armature = robot_model.armature\n",
    "# Terminal model following the same logic, although the integration is here trivial.\n",
    "terminalModel = crocoddyl.IntegratedActionModelEuler(\n",
    "    crocoddyl.DifferentialActionModelFreeFwdDynamics(state, actuationModel, terminalCostModel), 0.)\n",
    "terminalModel.differential.armature = robot_model.armature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_shoot\n",
    "problem = crocoddyl.ShootingProblem(robot_model.x0,\n",
    "                                    [runningModel_init] + [runningModel] * (HORIZON_LENGTH - 1),\n",
    "                                    terminalModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Working with the SQP solver of MIM\n",
    "The solver follows a very similar syntax to the DDP solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_solver\n",
    "solver = mim_solvers.SolverCSQP(problem)\n",
    "solver.with_callbacks = True \n",
    "solver.termination_tolerance = 1e-3         # Termination criteria (KKT residual)\n",
    "solver.max_qp_iters = 1000                  # Maximum number of QP iteration\n",
    "solver.eps_abs = 1e-5                       # QP termination absolute criteria, 1e-9 \n",
    "solver.eps_rel = 0.                         # QP termination absolute criteria\n",
    "solver.use_filter_line_search = True        # True by default, False = use merit function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now solver, and as usual plot the result and animate the motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_solve_and_plot\n",
    "# Solving it with the DDP algorithm\n",
    "solver.solve([],[],1000)  # xs_init,us_init,maxiter\n",
    "#assert( ddp.stop == 1.9384159634520916e-10 )\n",
    "\n",
    "ees = [ d.differential.pinocchio.oMf[FRAME_TIP].translation for d in solver.problem.runningDatas ]\n",
    "plt.plot(ees)\n",
    "plt.plot([0,HORIZON_LENGTH],[X_WALL_UPPER,X_WALL_UPPER],'b--')\n",
    "plt.plot([0,HORIZON_LENGTH],[X_WALL_LOWER,X_WALL_LOWER],'b--')\n",
    "plt.legend(['x', 'y', 'z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp5/generated/panda_reaches_with_constraints_animate\n",
    "# Visualizing the solution in gepetto-viewer\n",
    "viz.play([x[:robot.model.nq] for x in solver.xs],TIME_STEP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Homework\n",
    "Using all the content provided in this notebook, now write your own optimal control problem solving a 4-point sequences with virtual walls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The work plan is as follows:\n",
    "\n",
    "1. First take the 4-point OCP you wrote in the first part. The motion finally obtained is typically a circle containing the four target points. \n",
    "2. Add some bounds to sharpen the circle, so that the arcs are flattened by the virtual walls.\n",
    "3. Rewrite the motion objective with constraints, by imposing the targets passing points as constraints rather than defining them as costs. The constraints should then be equality, while they were inequalities up to now. This can be implemented by putting two equal bounds.\n",
    "4. Add joint limits. You will use the residual state for that. The bounds can be obtained from the URDF model through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_model.lowerPositionLimit, robot_model.upperPositionLimit, robot_model.velocityLimit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing to succeed to the 4 objectives is likely difficult and it is acceptable to only provide a solution with 2 or 3 of the items properly implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the described optimal control problem, solve it with MIM solver and display the result as an animation in MeshCat and by plotting the effector trajectory and the imposed Cartesian constraints, and the joint trajectories with respect to the joint limits.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
